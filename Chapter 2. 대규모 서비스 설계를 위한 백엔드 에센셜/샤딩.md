# 샤딩

: 관계형 데이터베이스에서 대량의 데이터를 처리하기위해 데이터를 파티셔닝(분할) 하는 기술.

샤딩은 DBMS 레벨에서 데이터를 나누는 것이 아니고 데이터 베이스 자체를 분할하는 방식이다. 따라서, 어플리케이션 레벨에서 구현해야 한다. 

**관련 용어**

### State

- 사라지지 않고 유지해야 하는 정보를 State라고 한다.
    
    ex) DB 정보들(stateful)
    
    - 단점 : 데이터 날라가면 난리난다.
- 유지하지 않아도 되는 데이터(Stateless)
    - Scrap 서버의 경우, 데이터가 없다면, 해당 데이터를 다시 접속하여 생성해서 서비스 할 수 있다.
    - GeoIp 서버의 경우도 해당 GeoIp를 호출해서 결과를 가져올 수 있다.
    - 쉽게 재생성할 수 있는 데이터
    - 실제 필요한 데이터를 DB에 저장하고 비즈니스 로직만 들고 있는 API 서버들은 대부분 Stateless하다.
    - stateless 한 서버는 LB 혹은 서비스 디스커버리를 통해서 확장해줄 수 있다.
    - 단점: 로직만 있어서 데이터를 가지려면 stateful한 서버로 가야한다.

### state서버의 확장은?

- state를 저장하는 DB 서버의 확장은 쉽지 않다. (scale up을 더 사용함, cpu, 메모리,ssb를 확장해주는 방법)
- 앞에서 우리는 읽기 분산을 통해서 부하를 분산하는 방법(Query off)를 알아보았다.

### 일반적인 DB 서버의 부하.

- 장비가 최대 한계가 Read+Write를 합쳐서 1000이라고 가정한다.
    
    800 reads/s , 200 writes/s 
    

![Untitled](%E1%84%89%E1%85%A3%E1%84%83%E1%85%B5%E1%86%BC%20eaa134a6390144d290b222ed6b80937d/Untitled.png)

읽기/쓰기로 나눌 경우 부하의 8이 secondary들로 감.

**Replica 장비를 추가하면 계속 성능이 좋아지게 될까?**

→ replica는 데이터의 복제가 필요하기때문에, write의 복제가 전부 같게 일어남 = write heavy situation

해결책: 더 좋은 장비를 사용하면 된다. (돈을 더 쓰면 됩니다.) (cpu,메모리가 다 높은)

### 그럼에도 더 이상 좋은 장비가 없다면?

: **database partitioning**

- Vertical partitioning
    - 하나의 Table을 컬럼 기준으로 나눈다.
    - 자주 사용하는 컬럼과 자주 사용하지 않는 컬럼으로 나눠서 성능을 향상시킬 수 있다.
        - 해당 테이블을 자주 쓰지 않는 컬럼의 데이터가 없어지므로, 테이블이 더 적은 사이즈를 차지하게 된다.
        
- Horizontal partitioning
    - 같은 Table을 데이터를 기준으로 나눈다. : 스키마가 동일
    - 데이터의 개수가 적어지므로 하나의 DB에서 처리해야 하는 부하가 줄어든다.
    - Horizontal Partitioning을 Sharding이라고 한다.
    - 여러대의 DB와 연결이 되어야 한다 라는 단점이 있다.

![Untitled](%E1%84%89%E1%85%A3%E1%84%83%E1%85%B5%E1%86%BC%20eaa134a6390144d290b222ed6b80937d/Untitled%201.png)

### Sharding에서 대두되는 이슈

- 데이터가 여러대의 DB에 저장된다면, 이제 어떤 데이터를 어디에 저장할 것인가를 알아야 한다.
- ID 3은 어디에 저장되어야 할까? ← sharding의 핵심 : 특정 key를 어디에 저장하고 어디서 찾을 것인지

### 특정 key를 어디에 저장하고 어디서 찾을 것인지에 대한 방법

- 짝수,홀수
- Range:특정 범위대역으로 나누기 ex) User 1000명당 하나의 서버로 나눈다.
    - 장점 : 새로운 shard를 추가하는것이 다른 방식보다 쉽다.
    - 단점: Shard간의 데이터가 균등하지 못할 가능성이 높다. ex) 1번shard는 사용자가 800명, 2번 shard는 사용자가 100명일 수 있다.
- Modular : 서버 대수로 나누기
    - %N
    - 장점 : 균등한 데이터의 분포 가능
    - 단점 : 서버가 추가 될 때마다 데이터의 이동이 심해진다.
    - 2배씩 증가하는게 유리하나. 이것도 시간이 지날 수록 많은 서버가 추가되어야 한다. (1대 → 2대→ 4대→ 8대→16대)
    - 특징 : Modular 방식을 사용할 때는 Preshard를 한 다음 Scale-Up을 가져가는 전략을 취하기도 한다.
- Indexed : 특정 데이터의 위치를 가리키는 서버가 존재
    - 장점: 데이터의 분배를 원하는 형태로 하기 쉽다
    - 단점: Indexed 자체가 하나의 서비스가 되어야 한다.
        - 관리 포인트의 증대
        - Indexed 자체가 SPOF가 될 수 있음
        

### 장애를 완화하려면?

- 요청 후에 User 위치 정보(서버 정보)를 저장하고 그 이후에는 가지고 있는 정보로 요청한다. : (client가 해당 정보를 처리할 수 있어야 가능)
- User 재 요청 경우
    - 새 접속 후에 유저 정보가 없을 경우
    - 유저 정보가 변경된 경우
        - 해당 서버에서 해당 유저 정보가 없다 라는 응답을 받을 경우
- Client가 자신의 정보를 가지고 있어야 하므로 이에 대한 구현이 필요하다.

⇒ 사실 복합적으로 쓰는게 제일 좋음

- Index 서버에는 Range가 들어가는게 좋다..
- 여러가지 형태를 다 섞은 형태
    - 여러가지 장점을 모두 취할 수 있음
- 구현이 복잡함

하 분필 소리 멈춰!!!!!!!!!!!!!!!!!

<실습> : range shard를 동적으로 구현하는 방법 

1. cd /the_red/zookeeper/bin
2. ./zkServer.sh start
3. ./zkCli.sh
4. ls  /
5. deleteall /the_red :하위 디렉토리 전부 지워주기

<탭2>

1. cd /the_red/chapter_2/shard/shard
2. vi app.ini : 주키퍼의 주소와 어떤 키를 쓸건지 등록해놓음
3. vi zoo_setup.py
4. replication을 걸진않았고, range를 정해둠

![Untitled](%E1%84%89%E1%85%A3%E1%84%83%E1%85%B5%E1%86%BC%20eaa134a6390144d290b222ed6b80937d/Untitled%202.png)

end가 -1이면, 3500보다 더 큰 값은 무조건 3번서버로 저장된다 뭐 이런 뜻.

data = {
"0": {"host": "redis0:127.0.0.1:16379", "start": 0, "end": 1000},
"1": {"host": "redis1:127.0.0.1:16380", "start": 1000, "end": 2000},
"2": {"host": "redis2:127.0.0.1:16381", "start": 2000, "end": -1}
}
#"3": {"host": "redis3:127.0.0.1:16382", "start": 3500, "end": -1}

: 하나 주석처리

1. python zoo_setup.py

<탭1>

1. get /the_red/storages/redis/shards/ranges : 들어있는 값을 볼 수 있음 

![Untitled](%E1%84%89%E1%85%A3%E1%84%83%E1%85%B5%E1%86%BC%20eaa134a6390144d290b222ed6b80937d/Untitled%203.png)

: 3개의 서버에 샤드가 만들어짐.

<탭2>

1. vi [main.py](http://main.py) :  refresh shard range로 shard가 바뀔때마다 shard정보를 다시 저장하는 manager를 볼 수 있음

Post를 쓰는 API

/api/v1/write_post/{user_id} : range를 검사하는 기능이 있음

해당 포스트를 하나만 읽음

/api/v1/posts/{user_id}/{post_id}

유저의 포스트를 전부 가져가오는 것

/api/v1/posts/{user_id}

: user_id 기준으로 range 샤딩을 하게됨 

1. vi [post.py](http://post.py) : 집어넣는건 user key로 sorted set에 넣고 있음, redis에 실제 post는 hash로 관리
2. ./start.sh 172.30.1.25:7001

![Untitled](%E1%84%89%E1%85%A3%E1%84%83%E1%85%B5%E1%86%BC%20eaa134a6390144d290b222ed6b80937d/Untitled%204.png)

1. [http://172.30.1.25:7001/api/v1/write_post/1?post_id=1&text=1](http://172.30.1.25:7001/api/v1/write_post/1?post_id=1&text=1) : redis 실행안돼서 에러남 

<탭3>

1. /the_red/chapter_2/shard/shard
2. vi docker-compose.yml : redis 띄우는 소스코드 
3. docker-compose up -d : redis 4대가 뜨게됨
4. 값들을 넣음

![Untitled](%E1%84%89%E1%85%A3%E1%84%83%E1%85%B5%E1%86%BC%20eaa134a6390144d290b222ed6b80937d/Untitled%205.png)

![Untitled](%E1%84%89%E1%85%A3%E1%84%83%E1%85%B5%E1%86%BC%20eaa134a6390144d290b222ed6b80937d/Untitled%206.png)

: key들이 들어감

그리고 주소 3을 되살려서 또 테스트 진행